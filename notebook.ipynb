{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model as l"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    # Read the data with its path location\n",
    "    try:\n",
    "        data = pd.read_csv(file_name)\n",
    "        return data\n",
    "    except Exception:\n",
    "        sys.exit(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def trainValTestSplit(data):\n",
    "    shuffled = data.sample(frac=1, random_state=0)\n",
    "    dataSize = len(shuffled)\n",
    "    train = shuffled[:int(dataSize * 0.7)]\n",
    "    val = shuffled[int(dataSize * 0.7):int(dataSize * 0.8)]\n",
    "    test = shuffled[int(dataSize * 0.8):]\n",
    "    return train, val, test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def normalize(X, min, max):\n",
    "    X = (X - min) / (max - min)\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_data(file_location):\n",
    "    data = read_data(file_location)\n",
    "\n",
    "    train, val, test = trainValTestSplit(data)\n",
    "    minVal = train.iloc[:, :-1].min()\n",
    "    maxVal = train.iloc[:, :-1].max()\n",
    "\n",
    "    X_train = np.array(normalize(train.iloc[:, :-1], minVal, maxVal))\n",
    "    X_val = np.array(normalize(val.iloc[:, :-1], minVal, maxVal))\n",
    "    X_test = np.array(normalize(test.iloc[:, :-1], minVal, maxVal))\n",
    "\n",
    "    y_train = np.array(train.iloc[:, -1:])\n",
    "    y_val = np.array(val.iloc[:, -1:])\n",
    "    y_test = np.array(test.iloc[:, -1:])\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "absolutePath = r'C:\\Users\\gulce\\Desktop\\EEE 8TH SEMESTER\\CS 464\\Homeworks\\HW2\\dataset.csv'\n",
    "# absolutePath = input('Enter the file location of the dataset: ')\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_data(absolutePath)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42000, 12)\n",
      "X_val shape: (6000, 12)\n",
      "X_test shape: (12000, 12)\n",
      "y_train shape: (42000, 1)\n",
      "y_val shape: (6000, 1)\n",
      "y_test shape: (12000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"y_val shape: {}\".format(y_val.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = l.LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def gaussianInitialization(dimension):\n",
    "    np.random.seed(9)\n",
    "    w = np.random.normal(loc=0, scale=1, size=(dimension, 1))\n",
    "    return w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def zeroInitialization(dimension):\n",
    "    np.random.seed(9)\n",
    "    w = np.zeros((dimension, 1))\n",
    "    return w\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, epochs=100, learningRate=0.001, batchSize=64):\n",
    "        self.epochs = epochs\n",
    "        self.learningRate = learningRate\n",
    "        self.batchSize = batchSize\n",
    "        self.i = i\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        m = X_train.shape[0]\n",
    "        w = zeroInitialization(X_train.shape[1])\n",
    "        b = zeroInitialization(1)\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch in range(m//self.batchSize + 1):\n",
    "                startIdx = batch*self.batchSize\n",
    "                endIdx = 2*batch*self.batchSize\n",
    "                if batch == m//self.batchSize:\n",
    "                    prob = sigmoid(np.dot(X_train[startIdx:endIdx], w) + b)\n",
    "                    dw = (1 / self.batchSize) * np.dot(X_train[startIdx:endIdx].T, (prob - y_train[startIdx:endIdx]))\n",
    "                    db = (1 / self.batchSize) * np.sum(prob - y_train[startIdx:endIdx])\n",
    "                else:\n",
    "                    prob = sigmoid(np.dot(X_train[startIdx:], w) + b)\n",
    "                    dw = (1 / self.batchSize) * np.dot(X_train[startIdx:].T, (prob - y_train[startIdx:]))\n",
    "                    db = (1 / self.batchSize) * np.sum(prob - y_train[batch])\n",
    "                w -= self.learningRate * dw\n",
    "                b -= self.learningRate * db\n",
    "            y_pred = model.predict(w, b, X_val, 0.5)\n",
    "            print('Acc for epoch', epoch, 'is: ', accuracy_score(y_pred, y_val))\n",
    "        return w, b\n",
    "\n",
    "    def predict(self, w, b, X, threshold):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        #w = w.reshape(X.shape[1], 1)\n",
    "        prob = sigmoid(np.dot(X, w) + b)\n",
    "        for i in range(prob.shape[0]):\n",
    "            if prob[i,0] > threshold:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "        return y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc for epoch 0 is:  0.6366666666666667\n",
      "Acc for epoch 1 is:  0.6366666666666667\n",
      "Acc for epoch 2 is:  0.6366666666666667\n",
      "Acc for epoch 3 is:  0.6366666666666667\n",
      "Acc for epoch 4 is:  0.6366666666666667\n",
      "Acc for epoch 5 is:  0.6366666666666667\n",
      "Acc for epoch 6 is:  0.6366666666666667\n",
      "Acc for epoch 7 is:  0.6366666666666667\n",
      "Acc for epoch 8 is:  0.6366666666666667\n",
      "Acc for epoch 9 is:  0.6366666666666667\n",
      "Acc for epoch 10 is:  0.6366666666666667\n",
      "Acc for epoch 11 is:  0.6366666666666667\n",
      "Acc for epoch 12 is:  0.6366666666666667\n",
      "Acc for epoch 13 is:  0.6366666666666667\n",
      "Acc for epoch 14 is:  0.6366666666666667\n",
      "Acc for epoch 15 is:  0.6366666666666667\n",
      "Acc for epoch 16 is:  0.6366666666666667\n",
      "Acc for epoch 17 is:  0.6366666666666667\n",
      "Acc for epoch 18 is:  0.6366666666666667\n",
      "Acc for epoch 19 is:  0.6366666666666667\n",
      "Acc for epoch 20 is:  0.6366666666666667\n",
      "Acc for epoch 21 is:  0.6366666666666667\n",
      "Acc for epoch 22 is:  0.6366666666666667\n",
      "Acc for epoch 23 is:  0.6366666666666667\n",
      "Acc for epoch 24 is:  0.6366666666666667\n",
      "Acc for epoch 25 is:  0.6366666666666667\n",
      "Acc for epoch 26 is:  0.6366666666666667\n",
      "Acc for epoch 27 is:  0.6366666666666667\n",
      "Acc for epoch 28 is:  0.6366666666666667\n",
      "Acc for epoch 29 is:  0.6366666666666667\n",
      "Acc for epoch 30 is:  0.6366666666666667\n",
      "Acc for epoch 31 is:  0.6366666666666667\n",
      "Acc for epoch 32 is:  0.6366666666666667\n",
      "Acc for epoch 33 is:  0.6366666666666667\n",
      "Acc for epoch 34 is:  0.6366666666666667\n",
      "Acc for epoch 35 is:  0.6366666666666667\n",
      "Acc for epoch 36 is:  0.6366666666666667\n",
      "Acc for epoch 37 is:  0.6366666666666667\n",
      "Acc for epoch 38 is:  0.6366666666666667\n",
      "Acc for epoch 39 is:  0.6366666666666667\n",
      "Acc for epoch 40 is:  0.6366666666666667\n",
      "Acc for epoch 41 is:  0.6366666666666667\n",
      "Acc for epoch 42 is:  0.6366666666666667\n",
      "Acc for epoch 43 is:  0.6366666666666667\n",
      "Acc for epoch 44 is:  0.6366666666666667\n",
      "Acc for epoch 45 is:  0.6366666666666667\n",
      "Acc for epoch 46 is:  0.6366666666666667\n",
      "Acc for epoch 47 is:  0.6366666666666667\n",
      "Acc for epoch 48 is:  0.6366666666666667\n",
      "Acc for epoch 49 is:  0.6366666666666667\n",
      "Acc for epoch 50 is:  0.6366666666666667\n",
      "Acc for epoch 51 is:  0.6366666666666667\n",
      "Acc for epoch 52 is:  0.6366666666666667\n",
      "Acc for epoch 53 is:  0.6366666666666667\n",
      "Acc for epoch 54 is:  0.6366666666666667\n",
      "Acc for epoch 55 is:  0.6366666666666667\n",
      "Acc for epoch 56 is:  0.6366666666666667\n",
      "Acc for epoch 57 is:  0.6366666666666667\n",
      "Acc for epoch 58 is:  0.6366666666666667\n",
      "Acc for epoch 59 is:  0.6366666666666667\n",
      "Acc for epoch 60 is:  0.6366666666666667\n",
      "Acc for epoch 61 is:  0.6366666666666667\n",
      "Acc for epoch 62 is:  0.6366666666666667\n",
      "Acc for epoch 63 is:  0.6366666666666667\n",
      "Acc for epoch 64 is:  0.6366666666666667\n",
      "Acc for epoch 65 is:  0.6366666666666667\n",
      "Acc for epoch 66 is:  0.6366666666666667\n",
      "Acc for epoch 67 is:  0.6366666666666667\n",
      "Acc for epoch 68 is:  0.6366666666666667\n",
      "Acc for epoch 69 is:  0.6366666666666667\n",
      "Acc for epoch 70 is:  0.6366666666666667\n",
      "Acc for epoch 71 is:  0.6366666666666667\n",
      "Acc for epoch 72 is:  0.6366666666666667\n",
      "Acc for epoch 73 is:  0.6366666666666667\n",
      "Acc for epoch 74 is:  0.6366666666666667\n",
      "Acc for epoch 75 is:  0.6366666666666667\n",
      "Acc for epoch 76 is:  0.6366666666666667\n",
      "Acc for epoch 77 is:  0.6366666666666667\n",
      "Acc for epoch 78 is:  0.6366666666666667\n",
      "Acc for epoch 79 is:  0.6366666666666667\n",
      "Acc for epoch 80 is:  0.6366666666666667\n",
      "Acc for epoch 81 is:  0.6366666666666667\n",
      "Acc for epoch 82 is:  0.6366666666666667\n",
      "Acc for epoch 83 is:  0.6366666666666667\n",
      "Acc for epoch 84 is:  0.6366666666666667\n",
      "Acc for epoch 85 is:  0.6366666666666667\n",
      "Acc for epoch 86 is:  0.6366666666666667\n",
      "Acc for epoch 87 is:  0.6366666666666667\n",
      "Acc for epoch 88 is:  0.6366666666666667\n",
      "Acc for epoch 89 is:  0.6366666666666667\n",
      "Acc for epoch 90 is:  0.6366666666666667\n",
      "Acc for epoch 91 is:  0.6366666666666667\n",
      "Acc for epoch 92 is:  0.6366666666666667\n",
      "Acc for epoch 93 is:  0.6366666666666667\n",
      "Acc for epoch 94 is:  0.6366666666666667\n",
      "Acc for epoch 95 is:  0.6366666666666667\n",
      "Acc for epoch 96 is:  0.6366666666666667\n",
      "Acc for epoch 97 is:  0.6366666666666667\n",
      "Acc for epoch 98 is:  0.6366666666666667\n",
      "Acc for epoch 99 is:  0.6366666666666667\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(100, 0.001, 10000)\n",
    "w, b = model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
